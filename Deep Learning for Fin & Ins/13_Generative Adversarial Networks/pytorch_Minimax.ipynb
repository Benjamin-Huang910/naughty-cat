{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://news.illinois.edu/files/6367/543635/116641.jpg\" alt=\"University of Illinois\" width=\"250\"/>\n",
        "\n",
        "# PyTorch implementation of Minimax #\n",
        "By Richard Sowers\n",
        "* <r-sowers@illinois.edu>\n",
        "* <https://publish.illinois.edu/r-sowers/>\n",
        "\n",
        "Copyright 2022 University of Illinois Board of Trustees. All Rights Reserved."
      ],
      "metadata": {
        "id": "_qoo0FsAPSdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy\n",
        "import pandas\n",
        "import time\n",
        "import random\n",
        "import matplotlib\n",
        "#%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "#from pandas.plotting import autocorrelation_plot\n",
        "import matplotlib.offsetbox as offsetbox\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "import sklearn.linear_model\n",
        "import sklearn.model_selection\n",
        "import itertools\n",
        "\n",
        "\n",
        "def saver(fname):\n",
        "    plt.savefig(fname+\".png\",bbox_inches=\"tight\")\n",
        "\n",
        "def legend(pos=\"bottom\",ncol=3):\n",
        "    if pos==\"bottom\":\n",
        "        plt.legend(bbox_to_anchor=(0.5,-0.2), loc='upper center',facecolor=\"lightgray\",ncol=ncol)\n",
        "    elif pos==\"side\":\n",
        "        plt.legend(bbox_to_anchor=(1.1,0.5), loc='center left',facecolor=\"lightgray\",ncol=1)\n",
        "\n",
        "def textbox(txt,fname=None):\n",
        "    plt.figure(figsize=(1,1))\n",
        "    plt.gca().add_artist(offsetbox.AnchoredText(\"\\n\".join(txt), loc=\"center\",prop=dict(size=30)))\n",
        "    plt.axis('off')\n",
        "    if fname is not None:\n",
        "        saver(fname)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "2YvIIuojPccN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEQ2mNw3WXw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for some reason, this needs to be in a separate cell\n",
        "params={\n",
        "    \"font.size\":15,\n",
        "    \"lines.linewidth\":5\n",
        "}\n",
        "plt.rcParams.update(params)"
      ],
      "metadata": {
        "id": "E6TRhuBaPhAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pngfiles=[f for f in os.listdir(\".\") if f.endswith(\".png\")]\n",
        "print(\"existing png files: \"+str(pngfiles))\n",
        "#print([os.remove(f) for f in pngfiles])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMLTStLoPjtw",
        "outputId": "fd09f775-864a-4ed5-99e2-932ea3b3e9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "existing png files: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getfile(location_pair,**kwargs): #tries to get local version and then defaults to google drive version\n",
        "    (loc,gdrive)=location_pair\n",
        "    try:\n",
        "        out=pandas.read_csv(loc,**kwargs)\n",
        "    except FileNotFoundError:\n",
        "        print(\"local file not found; accessing Google Drive\")\n",
        "        loc = 'https://drive.google.com/uc?export=download&id='+gdrive.split('/')[-2]\n",
        "        out=pandas.read_csv(loc,**kwargs)\n",
        "    return out"
      ],
      "metadata": {
        "id": "CQ7l-sHNPmH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# configuration variables"
      ],
      "metadata": {
        "id": "-kvsUGeUPor3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main"
      ],
      "metadata": {
        "id": "XrilKKeNPwVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableWrapper(torch.nn.Module):\n",
        "    #degenerate implementation of Module; forward returns the variable\n",
        "    def __init__(self,SEED=0):\n",
        "        super().__init__() #run init of torch.nn.Module\n",
        "        if SEED is not None:\n",
        "          torch.manual_seed(SEED)\n",
        "        self.variable = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "\n",
        "    def train(self,flag: bool):\n",
        "        self.requires_grad_(flag)\n",
        "\n",
        "    def get(self):\n",
        "        return self.variable.data.item()\n",
        "\n",
        "    def forward(self):\n",
        "        return self.variable\n",
        "\n",
        "X=VariableWrapper()\n",
        "Y=VariableWrapper()"
      ],
      "metadata": {
        "id": "p9j6vO1pWefH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x,y):\n",
        "  return (x-2*y)**2-7*(y-1)**2\n",
        "  # optimum is x=2, y=1\n",
        "\n",
        "optimizer = torch.optim.Adam(list(X.parameters())+list(Y.parameters()))"
      ],
      "metadata": {
        "id": "GIgxZogbeP0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_iter_outer=250\n",
        "MAX_iter_inner=10\n",
        "\n",
        "for ctr in range(MAX_iter_outer+1):\n",
        "\n",
        "  # minimize in X, hold Y constant\n",
        "  X.train(True)\n",
        "  Y.train(False)\n",
        "  for ctrprime in range(MAX_iter_inner):\n",
        "    optimizer.zero_grad()\n",
        "    (f(X(),Y())).backward() #evaluate loss and then backpropagate\n",
        "    optimizer.step()\n",
        "\n",
        "  # maximize in Y, hold X constant\n",
        "  X.train(False)\n",
        "  Y.train(True)\n",
        "  for ctrprime in range(MAX_iter_inner):\n",
        "    optimizer.zero_grad()\n",
        "    (-f(X(),Y())).backward() #evaluate negative loss and then backpropagate\n",
        "    optimizer.step()\n",
        "\n",
        "  loss=f(X(),Y())\n",
        "  if ctr%int(MAX_iter_outer/10)==0: #print out data for 10 intermediate steps\n",
        "      print(\"iteration {}: loss={:.3f},X={:.3f},Y={:.3f}\".format(ctr,loss.item(),X.get(),Y.get()),)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWJr_MVneXX2",
        "outputId": "9836be5d-d70c-49fc-fb26-818d53b6e1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss=-1.456,X=0.512,Y=0.506\n",
            "iteration 25: loss=0.313,X=0.895,Y=0.817\n",
            "iteration 50: loss=0.616,X=1.291,Y=1.042\n",
            "iteration 75: loss=0.272,X=1.645,Y=1.152\n",
            "iteration 100: loss=-0.003,X=1.912,Y=1.142\n",
            "iteration 125: loss=-0.020,X=2.045,Y=1.061\n",
            "iteration 150: loss=0.002,X=2.042,Y=0.997\n",
            "iteration 175: loss=-0.000,X=2.002,Y=0.992\n",
            "iteration 200: loss=0.000,X=1.997,Y=1.000\n",
            "iteration 225: loss=-0.000,X=2.000,Y=1.000\n",
            "iteration 250: loss=0.000,X=2.000,Y=1.000\n"
          ]
        }
      ]
    }
  ]
}