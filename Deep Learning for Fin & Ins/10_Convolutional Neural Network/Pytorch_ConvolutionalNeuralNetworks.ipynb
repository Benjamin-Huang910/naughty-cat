{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3V1oxg8jaBr"
      },
      "source": [
        "<img src=\"https://news.illinois.edu/files/6367/543635/116641.jpg\" alt=\"University of Illinois\" width=\"250\"/>\n",
        "\n",
        "# PyTorch CNN#\n",
        "By Richard Sowers\n",
        "* <r-sowers@illinois.edu>\n",
        "* <https://publish.illinois.edu/r-sowers/>\n",
        "\n",
        "Copyright 2020 University of Illinois Board of Trustees. All Rights Reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bly0YctuxsVp"
      },
      "source": [
        "# Imports and Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDtZ8c9V7OPo"
      },
      "source": [
        "import os\n",
        "import numpy\n",
        "import pandas\n",
        "idx = pandas.IndexSlice\n",
        "import time\n",
        "import random\n",
        "import matplotlib\n",
        "#%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "#from pandas.plotting import autocorrelation_plot\n",
        "import matplotlib.offsetbox as offsetbox\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
        "import graphviz\n",
        "\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "def saver(fname):\n",
        "    plt.savefig(fname+\".png\",bbox_inches=\"tight\")\n",
        "\n",
        "def legend(pos=\"bottom\",ncol=3):\n",
        "    if pos==\"bottom\":\n",
        "        plt.legend(bbox_to_anchor=(0.5,-0.2), loc='upper center',facecolor=\"lightgray\",ncol=ncol)\n",
        "    elif pos==\"side\":\n",
        "        plt.legend(bbox_to_anchor=(1.1,0.5), loc='center left',facecolor=\"lightgray\",ncol=1)\n",
        "\n",
        "def textbox(txt,fname=None):\n",
        "    plt.figure(figsize=(1,1))\n",
        "    plt.gca().add_artist(offsetbox.AnchoredText(\"\\n\".join(txt), loc=\"center\",prop=dict(size=30)))\n",
        "    plt.axis('off')\n",
        "    if fname is not None:\n",
        "        saver(fname)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQUScHLyJLXw"
      },
      "source": [
        "import torch\n",
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ShjrhqJjVN"
      },
      "source": [
        "#for some reason, this needs to be in a separate cell\n",
        "params={\n",
        "    \"font.size\":15,\n",
        "    \"lines.linewidth\":5,\n",
        "}\n",
        "plt.rcParams.update(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jXnBSIkkY7"
      },
      "source": [
        "def getfile(location_pair,**kwargs): #tries to get local version and then defaults to google drive version\n",
        "    (loc,gdrive)=location_pair\n",
        "    try:\n",
        "        out=pandas.read_csv(loc,**kwargs)\n",
        "    except FileNotFoundError:\n",
        "        print(\"local file not found; accessing Google Drive\")\n",
        "        loc = 'https://drive.google.com/uc?export=download&id='+gdrive.split('/')[-2]\n",
        "        out=pandas.read_csv(loc,**kwargs)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3-9S_ChuJOo"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARNO_YO3ssOW"
      },
      "source": [
        "SEED=0\n",
        "R=pandas.Series([3,4,4.5,5,5.5,6,6,6])\n",
        "R.index.name='n'\n",
        "\n",
        "signal_length=25\n",
        "N_trainingdata=1000\n",
        "N_trainingdata_visible=10\n",
        "plot_color=\"blue\"\n",
        "ref_color=\"red\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6xNxcbUu-OC"
      },
      "source": [
        "# Data #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofl9g-uJvA32"
      },
      "source": [
        "Let's synthesize some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znpCXZrMnGzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb758a26-96a4-44d1-8991-c0bd9f66807f"
      },
      "source": [
        "numpy.random.seed(SEED)\n",
        "errorsize=0.3\n",
        "trainingdata=pandas.DataFrame(scipy.stats.uniform.rvs(loc=0,scale=10,size=(signal_length,N_trainingdata)))\n",
        "trainingdata.index=pandas.RangeIndex(start=0,stop=signal_length,name=\"n\")\n",
        "\n",
        "p=0.5\n",
        "observations=range(1,N_trainingdata+1)\n",
        "\n",
        "labels=scipy.stats.bernoulli.rvs(p=p,size=N_trainingdata).astype(numpy.bool)\n",
        "labels[0]=True #force the first label for purposes of example\n",
        "\n",
        "positions=numpy.random.randint(low=0,high=signal_length-len(R),size=N_trainingdata)\n",
        "start=[(position if flag else None)  for (position,flag) in zip(positions,labels)]\n",
        "\n",
        "trainingdata.columns=pandas.MultiIndex.from_tuples(zip(observations,labels,start), names=('observation','label','start'))\n",
        "\n",
        "for ((observation,label,start),data) in trainingdata.iteritems():\n",
        "    if label:\n",
        "        trainingdata.loc[start+R.index,(observation,label,start)]=R.values+scipy.stats.norm.rvs(scale=errorsize,size=len(R))\n",
        "\n",
        "trainingdata.iloc[:,:N_trainingdata_visible]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-83a71a477091>:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  labels=scipy.stats.bernoulli.rvs(p=p,size=N_trainingdata).astype(numpy.bool)\n",
            "<ipython-input-6-83a71a477091>:17: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for ((observation,label,start),data) in trainingdata.iteritems():\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "observation        1         2         3         4         5         6   \\\n",
              "label           True      True      True      True      True      True    \n",
              "start              3         7         14        16        2         12   \n",
              "n                                                                         \n",
              "0            5.488135  7.151894  6.027634  5.448832  4.236548  6.458941   \n",
              "1            5.928803  0.100637  4.758262  7.087704  0.439754  8.795215   \n",
              "2            8.115185  4.760840  5.231560  2.505206  3.273137  3.029048   \n",
              "3            3.200046  6.296183  7.785843  8.515578  4.199965  1.660771   \n",
              "4            3.425321  5.665183  1.374144  3.497122  4.344949  3.790681   \n",
              "5            4.405654  2.976242  0.685996  3.525275  4.887139  7.629273   \n",
              "6            4.626292  4.286860  6.830566  6.009478  5.226124  1.574779   \n",
              "7            5.116113  3.283017  7.821373  8.870782  5.916336  9.736270   \n",
              "8            5.337272  4.636938  7.023351  2.073241  5.861973  3.660266   \n",
              "9            6.221898  4.174067  7.739527  1.288654  5.735266  9.420893   \n",
              "10           6.008898  4.819087  3.890231  0.376002  0.117877  9.962679   \n",
              "11           1.929642  5.603149  3.499245  2.039567  5.395283  5.694769   \n",
              "12           5.646904  5.801740  3.768837  4.996760  0.813024  3.160857   \n",
              "13           1.460074  5.674122  2.150975  5.175257  4.430306  4.183396   \n",
              "14           3.205951  6.416617  2.760340  8.539227  0.742608  4.903621   \n",
              "15           3.861379  7.124766  4.392262  4.631377  9.436460  4.751738   \n",
              "16           3.955374  8.440175  4.786564  3.193514  0.945702  5.646461   \n",
              "17           7.373720  4.326853  5.102961  3.609605  5.568422  6.246163   \n",
              "18           8.140271  8.513372  5.410462  4.109265  4.766588  6.263952   \n",
              "19           4.584133  7.410239  5.961331  4.670122  1.124417  5.805661   \n",
              "20           3.921730  0.411566  6.221989  5.425994  9.442822  7.227245   \n",
              "21           6.673423  1.566746  6.006957  5.886720  5.035823  9.645179   \n",
              "22           9.809375  2.796233  3.147529  6.147698  6.989326  2.434891   \n",
              "23           3.114064  1.041135  3.917840  6.050832  0.512884  2.440081   \n",
              "24           1.531962  0.328116  2.287953  4.992464  2.953894  6.477148   \n",
              "\n",
              "observation        7         8         9         10  \n",
              "label           False     True      False     True   \n",
              "start             NaN        14       NaN        11  \n",
              "n                                                    \n",
              "0            4.375872  8.917730  9.636628  3.834415  \n",
              "1            5.200814  0.306610  2.244136  9.536757  \n",
              "2            5.772840  1.696781  1.594691  4.170297  \n",
              "3            8.283896  0.586291  2.001707  6.229267  \n",
              "4            1.141513  5.618129  6.415937  9.870915  \n",
              "5            1.116283  1.436810  2.785103  2.880268  \n",
              "6            0.705557  0.345901  7.760049  8.509589  \n",
              "7            3.441207  3.991273  3.676832  8.443634  \n",
              "8            3.406353  1.205241  8.545623  6.681478  \n",
              "9            1.616041  6.291562  2.357657  5.155481  \n",
              "10           4.881967  3.720248  1.961721  8.071922  \n",
              "11           7.795808  6.955145  2.458042  3.186013  \n",
              "12           9.156513  8.534524  5.941565  4.477605  \n",
              "13           2.800170  7.660889  0.778728  3.945079  \n",
              "14           9.194540  3.722249  8.498853  4.746917  \n",
              "15           9.444667  4.173656  1.540525  5.594499  \n",
              "16           0.097992  4.486879  9.775355  5.862205  \n",
              "17           9.023878  4.772629  2.740643  6.254212  \n",
              "18           0.600628  5.790413  3.375102  6.014361  \n",
              "19           0.365192  6.151214  5.814854  5.751339  \n",
              "20           9.183200  6.349082  6.468967  0.679390  \n",
              "21           3.270953  6.563152  3.807635  5.923797  \n",
              "22           5.302360  0.323033  4.315719  2.541595  \n",
              "23           1.309402  5.143186  6.855157  6.382071  \n",
              "24           9.351780  7.169902  1.822346  2.691856  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a1efd73-bdb2-4f7d-a2c2-ad7a2c6952de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>observation</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>True</th>\n",
              "      <th>True</th>\n",
              "      <th>True</th>\n",
              "      <th>True</th>\n",
              "      <th>True</th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>start</th>\n",
              "      <th>3</th>\n",
              "      <th>7</th>\n",
              "      <th>14</th>\n",
              "      <th>16</th>\n",
              "      <th>2</th>\n",
              "      <th>12</th>\n",
              "      <th>NaN</th>\n",
              "      <th>14</th>\n",
              "      <th>NaN</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.488135</td>\n",
              "      <td>7.151894</td>\n",
              "      <td>6.027634</td>\n",
              "      <td>5.448832</td>\n",
              "      <td>4.236548</td>\n",
              "      <td>6.458941</td>\n",
              "      <td>4.375872</td>\n",
              "      <td>8.917730</td>\n",
              "      <td>9.636628</td>\n",
              "      <td>3.834415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.928803</td>\n",
              "      <td>0.100637</td>\n",
              "      <td>4.758262</td>\n",
              "      <td>7.087704</td>\n",
              "      <td>0.439754</td>\n",
              "      <td>8.795215</td>\n",
              "      <td>5.200814</td>\n",
              "      <td>0.306610</td>\n",
              "      <td>2.244136</td>\n",
              "      <td>9.536757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.115185</td>\n",
              "      <td>4.760840</td>\n",
              "      <td>5.231560</td>\n",
              "      <td>2.505206</td>\n",
              "      <td>3.273137</td>\n",
              "      <td>3.029048</td>\n",
              "      <td>5.772840</td>\n",
              "      <td>1.696781</td>\n",
              "      <td>1.594691</td>\n",
              "      <td>4.170297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.200046</td>\n",
              "      <td>6.296183</td>\n",
              "      <td>7.785843</td>\n",
              "      <td>8.515578</td>\n",
              "      <td>4.199965</td>\n",
              "      <td>1.660771</td>\n",
              "      <td>8.283896</td>\n",
              "      <td>0.586291</td>\n",
              "      <td>2.001707</td>\n",
              "      <td>6.229267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.425321</td>\n",
              "      <td>5.665183</td>\n",
              "      <td>1.374144</td>\n",
              "      <td>3.497122</td>\n",
              "      <td>4.344949</td>\n",
              "      <td>3.790681</td>\n",
              "      <td>1.141513</td>\n",
              "      <td>5.618129</td>\n",
              "      <td>6.415937</td>\n",
              "      <td>9.870915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.405654</td>\n",
              "      <td>2.976242</td>\n",
              "      <td>0.685996</td>\n",
              "      <td>3.525275</td>\n",
              "      <td>4.887139</td>\n",
              "      <td>7.629273</td>\n",
              "      <td>1.116283</td>\n",
              "      <td>1.436810</td>\n",
              "      <td>2.785103</td>\n",
              "      <td>2.880268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.626292</td>\n",
              "      <td>4.286860</td>\n",
              "      <td>6.830566</td>\n",
              "      <td>6.009478</td>\n",
              "      <td>5.226124</td>\n",
              "      <td>1.574779</td>\n",
              "      <td>0.705557</td>\n",
              "      <td>0.345901</td>\n",
              "      <td>7.760049</td>\n",
              "      <td>8.509589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.116113</td>\n",
              "      <td>3.283017</td>\n",
              "      <td>7.821373</td>\n",
              "      <td>8.870782</td>\n",
              "      <td>5.916336</td>\n",
              "      <td>9.736270</td>\n",
              "      <td>3.441207</td>\n",
              "      <td>3.991273</td>\n",
              "      <td>3.676832</td>\n",
              "      <td>8.443634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.337272</td>\n",
              "      <td>4.636938</td>\n",
              "      <td>7.023351</td>\n",
              "      <td>2.073241</td>\n",
              "      <td>5.861973</td>\n",
              "      <td>3.660266</td>\n",
              "      <td>3.406353</td>\n",
              "      <td>1.205241</td>\n",
              "      <td>8.545623</td>\n",
              "      <td>6.681478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.221898</td>\n",
              "      <td>4.174067</td>\n",
              "      <td>7.739527</td>\n",
              "      <td>1.288654</td>\n",
              "      <td>5.735266</td>\n",
              "      <td>9.420893</td>\n",
              "      <td>1.616041</td>\n",
              "      <td>6.291562</td>\n",
              "      <td>2.357657</td>\n",
              "      <td>5.155481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.008898</td>\n",
              "      <td>4.819087</td>\n",
              "      <td>3.890231</td>\n",
              "      <td>0.376002</td>\n",
              "      <td>0.117877</td>\n",
              "      <td>9.962679</td>\n",
              "      <td>4.881967</td>\n",
              "      <td>3.720248</td>\n",
              "      <td>1.961721</td>\n",
              "      <td>8.071922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.929642</td>\n",
              "      <td>5.603149</td>\n",
              "      <td>3.499245</td>\n",
              "      <td>2.039567</td>\n",
              "      <td>5.395283</td>\n",
              "      <td>5.694769</td>\n",
              "      <td>7.795808</td>\n",
              "      <td>6.955145</td>\n",
              "      <td>2.458042</td>\n",
              "      <td>3.186013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5.646904</td>\n",
              "      <td>5.801740</td>\n",
              "      <td>3.768837</td>\n",
              "      <td>4.996760</td>\n",
              "      <td>0.813024</td>\n",
              "      <td>3.160857</td>\n",
              "      <td>9.156513</td>\n",
              "      <td>8.534524</td>\n",
              "      <td>5.941565</td>\n",
              "      <td>4.477605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.460074</td>\n",
              "      <td>5.674122</td>\n",
              "      <td>2.150975</td>\n",
              "      <td>5.175257</td>\n",
              "      <td>4.430306</td>\n",
              "      <td>4.183396</td>\n",
              "      <td>2.800170</td>\n",
              "      <td>7.660889</td>\n",
              "      <td>0.778728</td>\n",
              "      <td>3.945079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.205951</td>\n",
              "      <td>6.416617</td>\n",
              "      <td>2.760340</td>\n",
              "      <td>8.539227</td>\n",
              "      <td>0.742608</td>\n",
              "      <td>4.903621</td>\n",
              "      <td>9.194540</td>\n",
              "      <td>3.722249</td>\n",
              "      <td>8.498853</td>\n",
              "      <td>4.746917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.861379</td>\n",
              "      <td>7.124766</td>\n",
              "      <td>4.392262</td>\n",
              "      <td>4.631377</td>\n",
              "      <td>9.436460</td>\n",
              "      <td>4.751738</td>\n",
              "      <td>9.444667</td>\n",
              "      <td>4.173656</td>\n",
              "      <td>1.540525</td>\n",
              "      <td>5.594499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.955374</td>\n",
              "      <td>8.440175</td>\n",
              "      <td>4.786564</td>\n",
              "      <td>3.193514</td>\n",
              "      <td>0.945702</td>\n",
              "      <td>5.646461</td>\n",
              "      <td>0.097992</td>\n",
              "      <td>4.486879</td>\n",
              "      <td>9.775355</td>\n",
              "      <td>5.862205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7.373720</td>\n",
              "      <td>4.326853</td>\n",
              "      <td>5.102961</td>\n",
              "      <td>3.609605</td>\n",
              "      <td>5.568422</td>\n",
              "      <td>6.246163</td>\n",
              "      <td>9.023878</td>\n",
              "      <td>4.772629</td>\n",
              "      <td>2.740643</td>\n",
              "      <td>6.254212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.140271</td>\n",
              "      <td>8.513372</td>\n",
              "      <td>5.410462</td>\n",
              "      <td>4.109265</td>\n",
              "      <td>4.766588</td>\n",
              "      <td>6.263952</td>\n",
              "      <td>0.600628</td>\n",
              "      <td>5.790413</td>\n",
              "      <td>3.375102</td>\n",
              "      <td>6.014361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.584133</td>\n",
              "      <td>7.410239</td>\n",
              "      <td>5.961331</td>\n",
              "      <td>4.670122</td>\n",
              "      <td>1.124417</td>\n",
              "      <td>5.805661</td>\n",
              "      <td>0.365192</td>\n",
              "      <td>6.151214</td>\n",
              "      <td>5.814854</td>\n",
              "      <td>5.751339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.921730</td>\n",
              "      <td>0.411566</td>\n",
              "      <td>6.221989</td>\n",
              "      <td>5.425994</td>\n",
              "      <td>9.442822</td>\n",
              "      <td>7.227245</td>\n",
              "      <td>9.183200</td>\n",
              "      <td>6.349082</td>\n",
              "      <td>6.468967</td>\n",
              "      <td>0.679390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.673423</td>\n",
              "      <td>1.566746</td>\n",
              "      <td>6.006957</td>\n",
              "      <td>5.886720</td>\n",
              "      <td>5.035823</td>\n",
              "      <td>9.645179</td>\n",
              "      <td>3.270953</td>\n",
              "      <td>6.563152</td>\n",
              "      <td>3.807635</td>\n",
              "      <td>5.923797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>9.809375</td>\n",
              "      <td>2.796233</td>\n",
              "      <td>3.147529</td>\n",
              "      <td>6.147698</td>\n",
              "      <td>6.989326</td>\n",
              "      <td>2.434891</td>\n",
              "      <td>5.302360</td>\n",
              "      <td>0.323033</td>\n",
              "      <td>4.315719</td>\n",
              "      <td>2.541595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3.114064</td>\n",
              "      <td>1.041135</td>\n",
              "      <td>3.917840</td>\n",
              "      <td>6.050832</td>\n",
              "      <td>0.512884</td>\n",
              "      <td>2.440081</td>\n",
              "      <td>1.309402</td>\n",
              "      <td>5.143186</td>\n",
              "      <td>6.855157</td>\n",
              "      <td>6.382071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.531962</td>\n",
              "      <td>0.328116</td>\n",
              "      <td>2.287953</td>\n",
              "      <td>4.992464</td>\n",
              "      <td>2.953894</td>\n",
              "      <td>6.477148</td>\n",
              "      <td>9.351780</td>\n",
              "      <td>7.169902</td>\n",
              "      <td>1.822346</td>\n",
              "      <td>2.691856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a1efd73-bdb2-4f7d-a2c2-ad7a2c6952de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a1efd73-bdb2-4f7d-a2c2-ad7a2c6952de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a1efd73-bdb2-4f7d-a2c2-ad7a2c6952de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-803fd131-8b2a-41b2-8627-10a72c15e069\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-803fd131-8b2a-41b2-8627-10a72c15e069')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-803fd131-8b2a-41b2-8627-10a72c15e069 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hEjtBjRvWa4",
        "outputId": "9a8e4cea-49fd-4549-ff02-38e27efcf6d8"
      },
      "source": [
        "#make inputs\n",
        "#tensor\n",
        "# want first dimension to be observationnumber\n",
        "# for each observation, want 1 channel of len(trainingdata)\n",
        "torch_features=torch.from_numpy(trainingdata.values.transpose().reshape(-1,1,len(trainingdata))).type(torch.float)\n",
        "print(\"first observation in torch:\",torch_features[0,:])\n",
        "print(\"first observation in pandas: \",trainingdata.iloc[:,0].values)\n",
        "\n",
        "# make labels\n",
        "_,labels,_=zip(*trainingdata.columns)\n",
        "torch_labels=torch.from_numpy(numpy.array(labels).reshape(-1,1)).type(torch.float)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first observation in torch: tensor([[5.4881, 5.9288, 8.1152, 3.2000, 3.4253, 4.4057, 4.6263, 5.1161, 5.3373,\n",
            "         6.2219, 6.0089, 1.9296, 5.6469, 1.4601, 3.2060, 3.8614, 3.9554, 7.3737,\n",
            "         8.1403, 4.5841, 3.9217, 6.6734, 9.8094, 3.1141, 1.5320]])\n",
            "first observation in pandas:  [5.48813504 5.92880271 8.11518471 3.20004643 3.42532118 4.40565362\n",
            " 4.62629233 5.11611256 5.33727162 6.22189817 6.0088977  1.92964246\n",
            " 5.64690403 1.46007399 3.20595056 3.86137859 3.95537377 7.37372011\n",
            " 8.14027103 4.58413253 3.92172961 6.67342349 9.80937541 3.11406359\n",
            " 1.53196185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWcgvD4ittbt"
      },
      "source": [
        "# 1d Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjgHm9Imt45G"
      },
      "source": [
        "Let's make sure that we understand PyTorch 1d convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRg8q316xBc5",
        "outputId": "c4346d34-687c-476c-fa3a-a5bdc0a699df"
      },
      "source": [
        "torch.manual_seed(SEED)\n",
        "in_channels=1\n",
        "out_channels=1\n",
        "batchsize=1\n",
        "kernel_size=len(R)\n",
        "CNN_test = torch.nn.Conv1d(in_channels, out_channels, kernel_size)\n",
        "CNN_test.weight.data=torch.tensor(R.values.reshape(CNN_test.weight.data.shape)).type(torch.float)\n",
        "print(\"weight: \",CNN_test.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight:  tensor([[[3.0000, 4.0000, 4.5000, 5.0000, 5.5000, 6.0000, 6.0000, 6.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq2avh3hz8u9",
        "outputId": "62f8a6cf-73b0-43f8-be13-306abc2b2583"
      },
      "source": [
        "print(\"output from CNN: \",CNN_test(torch_features[0:1]))\n",
        "print(\"output from numpy correlate: \",numpy.correlate(trainingdata.iloc[:,0],R.values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output from CNN:  tensor([[[196.3944, 196.4517, 200.0529, 199.7740, 188.5837, 197.1327, 176.7078,\n",
            "          167.1997, 159.7787, 153.7544, 167.2009, 188.9990, 198.8266, 194.7580,\n",
            "          215.5470, 248.8972, 240.0322, 218.3244]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "output from numpy correlate:  [196.42579686 196.4831158  200.0842552  199.80535101 188.61508025\n",
            " 197.16409995 176.73920065 167.23105947 159.8100505  153.785821\n",
            " 167.23226396 189.03040098 198.85797631 194.78935639 215.57835307\n",
            " 248.92862656 240.0635719  218.35572324]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Mux_Fj2o5L"
      },
      "source": [
        "# CNN test class #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZBh4HFb3XCC"
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self,kernel_size,observation_length,SEED=0):\n",
        "    super().__init__()\n",
        "    if SEED is not None:\n",
        "          torch.manual_seed(SEED)\n",
        "    in_channels=1\n",
        "    out_channels=1\n",
        "    self.conv1d = torch.nn.Conv1d(in_channels, out_channels, kernel_size,padding='same')\n",
        "    # padding=same means output will be same size as input\n",
        "    self.maxpool = torch.nn.MaxPool1d(observation_length)\n",
        "    self.linear=torch.nn.Linear(out_channels,1)\n",
        "    self.sigmoid=torch.nn.Sigmoid()\n",
        "    self.ReLU=torch.nn.ReLU()\n",
        "    if torch.cuda.is_available():\n",
        "        \"converting to cuda\"\n",
        "        self = self.cuda()\n",
        "\n",
        "  def forward(self,input):\n",
        "    out=self.conv1d(input)\n",
        "    out=self.ReLU(out)\n",
        "    out=self.maxpool(out)\n",
        "    out=torch.flatten(out,1)\n",
        "    out=self.linear(out)\n",
        "    out=self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "Loss = torch.nn.BCELoss()\n",
        "\n",
        "myCNN=CNN(len(R),len(trainingdata),SEED=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpSpOihmrrqe",
        "outputId": "54ca4cea-acba-4ea5-b69a-e2d2997cad00"
      },
      "source": [
        "optimizer = torch.optim.Adam(myCNN.parameters())\n",
        "losses=[]\n",
        "MAX_iter=10000\n",
        "for ctr in range(MAX_iter):\n",
        "\n",
        "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get output from the model, given the inputs\n",
        "    outputs = myCNN(torch_features)\n",
        "\n",
        "    # get loss for the predicted output\n",
        "    lossvalue = Loss(outputs, torch_labels)\n",
        "    losses.append(lossvalue)\n",
        "\n",
        "    # get gradients w.r.t to parameters\n",
        "    lossvalue.backward()\n",
        "    #print(model.linear.weight.grad.item(),model.linear.bias.grad.item())\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    if ctr%int(MAX_iter/10)==0: #print out data for 10 intermediate steps\n",
        "      print(\"iteration {}: loss={:.5f}\".format(ctr, lossvalue.item()))\n",
        "\n",
        "print(\"final loss={:.5f}\".format(lossvalue.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1008.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss=0.68175\n",
            "iteration 1000: loss=0.64478\n",
            "iteration 2000: loss=0.62681\n",
            "iteration 3000: loss=0.62648\n",
            "iteration 4000: loss=0.62643\n",
            "iteration 5000: loss=0.62639\n",
            "iteration 6000: loss=0.62639\n",
            "iteration 7000: loss=0.62639\n",
            "iteration 8000: loss=0.62639\n",
            "iteration 9000: loss=0.62639\n",
            "final loss=0.62639\n"
          ]
        }
      ]
    }
  ]
}